# ðŸŽ¨ðŸ§ ðŸŽµ Synesthesia Studio
**Express your emotions across modalities â€” from drawing to sound.**  
This prototype uses **AI** to interpret an uploaded drawing or image, extract its emotional tone and visual features, and generate corresponding **music parameters** and an **8-bar MIDI melody** using **Magenta**.

---

## âœ¨ Overview

Many people express themselves through different forms â€” some through **visual art**, others through **music**.  
This prototype bridges modalities:  
- **Upload a drawing** â†’  
- **AI interprets its emotion and style** â†’  
- **Extracts features** (color, balance, texture) â†’  
- **Maps to music parameters** (tempo, mode, chords, articulation) â†’  
- **Generates a primer melody** â†’  
- **Runs Magenta** to create a full **MIDI piece** you can play.

---

## ðŸ§  System Architecture

```plaintext
User Uploads Image
       â†“
[ Next.js Frontend (page.js) ]
  - Upload + GPT analysis
  - Extract visual features
  - Map to music parameters
  - Build 8-bar primer JSON
       â†“
[ API Route (route.js) ]
  - Receives JSON
  - Calls Python Magenta script
       â†“
[ Python Script (generatemelody.py) ]
  - Runs `melody_rnn_generate`
  - Saves MIDI file
       â†“
[ Output MIDI ]
  - Shown/downloadable on web

